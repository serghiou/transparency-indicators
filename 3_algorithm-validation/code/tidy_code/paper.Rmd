---
title: 'Indicators of transparency: Algorithm validation'
author: "Stylianos Serghiou"
date: '`r format(Sys.time(), "%d/%m/%Y")`'
params:
  n:
    label: "Fraction of total data to include in analysis"
    value: 3000
    input: slider
    min: 0
    max: 5000
    step: 100
output:
  prettydoc::html_pretty:
    # no code_folding available
    theme: hpstr      # or: architect; https://github.com/yixuan/prettydoc
    highlight: github # or: vignette
    toc: TRUE         # no toc_float available
    df_print: kable   # obviates %>% kable; does not replace styling though
  tufte::tufte_handout: default
  pdf_document:
    highlight: tango
    df_print: kable
    latex_engine: pdflatex
    keep_tex: yes
  rmdformats::readthedown:
    highlight: kate
    df_print: kable    # obviates %>% kable; does not replace styling though
    code_folding: hide # or: show; (comment out to not give option)
  tufte::tufte_html: 
    toc: TRUE
  epuRate::epurate:
    df_print: kable
    toc: yes
  html_document:
    highlight: tango
    theme: sandstone
    df_print: kable
    toc: yes
    toc_depth: 2
    toc_float: yes
    css: "path_to_custom.css"
header-includes:
- \DeclareUnicodeCharacter{3B8}{~}
- \DeclareUnicodeCharacter{3B1}{~}
- \DeclareUnicodeCharacter{3B2}{~}
- \DeclareUnicodeCharacter{223C}{~}
- \DeclareUnicodeCharacter{2264}{~}
- \DeclareUnicodeCharacter{2265}{~}
- \DeclareUnicodeCharacter{2581}{~}
- \DeclareUnicodeCharacter{2582}{~}
- \DeclareUnicodeCharacter{2583}{~}
- \DeclareUnicodeCharacter{2585}{~}
- \DeclareUnicodeCharacter{2586}{~}
- \DeclareUnicodeCharacter{2587}{~} 
- \DeclareUnicodeCharacter{FB00}{~} 
- \usepackage{graphicx}
editor_options: 
  chunk_output_type: inline
---

<style>
p {

text-align: justify;
text-justify: interword;
padding: 0 0 0.5em 0

}
</style>

```{r knitr, echo=FALSE}
# Load packages
library(knitr)
library(rmdformats)
library(kableExtra)
library(ggplot2)
library(magrittr)



######### knitr

# Define chunk options
opts_chunk$set(echo = TRUE
               , cache     = FALSE      # if TRUE, no need to rerun chunks
               #, cache.lazy = TRUE     # use when have big objects (>1 GB)
               , cache.comments = FALSE # do not rebuild if comments change
               , tidy      = FALSE      # can play with this
               , warning   = FALSE 
               , message   = FALSE
               , comment   = NA
               , fig.align = "center"
               , fig.width = 7
               # , fig.path  = "Figs/" # export all figures to dir Figs
               , linewidth = 91)

opts_knit$set(width = 75)

# Initiatialize hook
hook_output = knit_hooks$get("output")

# Hook to wrap output text when it exceeds 'n' using linewidth
knit_hooks$set(output = function(x, options) {
  
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    
    # wrap lines wider than 'n' 
    if (any(nchar(x) > n)) 
      x <- strwrap(x, width = n)
      x <- paste(x, collapse = "\n")
  }
  hook_output(x, options)
})

# For more knitr options visit: https://yihui.name/knitr/options/
# and his github page: https://github.com/yihui/knitr-examples



######### kableExtra

options(knitr.kable.NA = ''  # replace NAs in tables with blank
        , digits = 3)          # round digits (doesn't work without this here!)

## Example use
# data.frame(x = c(1,2,3), y = c(4,5,6), z = c(7,8,9)) %>% 
#   kable(booktabs = T) %>% kable_styling()

# Function to simplify table styling
sable <- function(tab, escape = T, full_width = F, drop = F, font_size = 12) {
  if (drop) {
    tab %>%
      kable(escape = escape, booktabs = T) %>%
      collapse_rows(valign = "top") %>% 
      kable_styling("striped", 
                    position = "center", 
                    full_width = full_width, 
                    font_size = font_size)
  } else {
    tab %>%
      kable(escape = escape, booktabs = T) %>%
      kable_styling("striped", 
                    position = "center", 
                    full_width = full_width,
                    font_size = font_size)
  }
}

## Guidelines
# No longer need to define options(knitr.table.format = "html"). It is now automatically done as soon as you load kableExtra
# No need to run kable() every time - done automatically as soon as you load kableExtra
# Loading kableExtra nullifies any styling applied by df_table: kable in the preamble - if you are content with standard formatting, DO NOT load kableExtra



#########  ggplot2

# Set up preferred theme in ggplot2
my_theme <- 
  # this and theme_minimal() are my favorite
  theme_light() +  
  theme(
    text = element_text(color = "grey20"),
    title = element_text(face = "bold"),
    legend.key = element_rect(colour = NA, fill = NA),  # Avoid borders
    panel.border = element_blank(), 
    axis.ticks = element_blank(),
    axis.title = element_text(face = "bold")
  )

# Make the above theme the default theme
original_theme <- theme_set(my_theme)

# Use ggsave to save plots after plotting - this reduces size dramatically



######### Live preview

# Preview the HTML without having to re-knit
# https://www.r-bloggers.com/create-r-markdown-reports-and-presentations-even-better-with-these-3-practical-tips/amp/

# xaringan::infinite_moon_reader()




######### Tabbed sections

# You can organize content using tabs by applying the .tabset class attribute to headers within a document. This will cause all sub-headers of the header with the .tabset attribute to appear within tabs rather than as standalone sections. For example:

## Quarterly Results {.tabset}

### By Product



######### Update package

# To update the package use:
# Replace ~/serghiouTemplates/inst/rmarkdown/templates/report/skeleton.rmd
# library(devtools); setwd("/Users/Stelios/"); install("serghiouTemplates")
```


# Setup {.tabset}

```{r setup_1}
# Load packages
library(cowplot)
library(doRNG)  # To set seed in multiple cores
library(foreach)
library(magrittr)
library(parallel)
library(readxl)
library(tidyverse)

# Paths
tidy_data <- "../../data/tidy_data"
figure_output <- "../../output/figure_output"

# Source
source("utils.R")
```


Parallelize.

```{r}
cl <- parallel::makeCluster(8L)
pkgs <- c("magrittr", "tidyverse")
```


```{r, echo=FALSE}
message(paste("Using", params$n, "boostrap iterations."))
print(paste("Using", params$n, "boostrap iterations."))
```


***


# Data

## Prepare data

```{r}
# Import
df_true  <- read_excel(file.path(tidy_data, "data_true.xlsx"))
df_false <- read_excel(file.path(tidy_data, "data_false.xlsx"))
```

```{r}
out_data <- list()
```


Setup variables.

```{r}
# Filter for the population of articles we are willing to consider
filtering_vars <- syms(c(
  "isResearch",  # IMPORTANT
  "is_xml"
))

# Sampling strata for articles initially predicted positive
grouping_vars_true <- syms(c(
  ""
))

# Sampling strata for articles initially predicted negative
grouping_vars_false <- syms(c(
  ""
))

# Definitions of prediction and labels
pred_label_vars <- syms(c(
  "is_open_data",  # this is what the algorithm said
  "isData",
  "is_effective",
  "is_active",
  "is_per_paper"
))
```


## Evaluate

Active sharing in all articles.

```{r}
# Set seed
set.seed(1306)

# Expected value
expected_vals <- 
  eval_no_boot(
    type = "active", 
    is_old = F, 
    filters = filtering_vars[0],
    pred_label = pred_label_vars[c(1, 4)]
  ) %>% 
  gather(metric, expected)

# Run bootstrap
df_any <- foreach(1:params$n, .combine = bind_rows, .packages = pkgs) %dorng%
  eval_boot(
    type = "active", 
    is_old = F, 
    filters = filtering_vars[0],
    pred_label = pred_label_vars[c(1, 4)]
  )

# Summarize
out_data$data_eval_active <- 
  df_any %>% 
  eval_summarize() %>% 
  left_join(expected_vals)

# Print
out_data$data_eval_active %>% 
  sable()
```


*** 


# Code

## Prepare data

```{r}
# Import
df_true   <- read_excel(file.path(tidy_data, "data_true.xlsx"))
df_false  <- read_excel(file.path(tidy_data, "data_false.xlsx"))
true_code <- read_excel(file.path(tidy_data, "code_true.xlsx"))
```

```{r}
out_code <- list()
```


Setup variables.

```{r}
# Filter for the population of articles we are willing to consider
filtering_vars <- syms(c(
  "isResearch",
  "is_xml"
))

# Sampling strata for articles initially predicted positive
grouping_vars_true <- syms(c(
  ""
))

# Sampling strata for articles initially predicted negative
grouping_vars_false <- syms(c(
  "is_open_data"
))

# Definitions of prediction and labels
pred_label_vars <- syms(c(
  "is_open_code", 
  "isCode",
  "is_effective_code",
  "is_active_code"
))
```


## Evaluate

Active sharing in any article.

```{r}
# Set seed
set.seed(1306)

# Expected value
expected_vals <- 
  eval_no_boot(
    t_tr = true_code,
    t_fs = bind_rows(df_true, df_false),
    type = "active", 
    is_old = F, 
    filters = filtering_vars[0],
    grouping_fs = grouping_vars_false[1],
    pred_label = pred_label_vars[c(1, 4)]
  ) %>% 
  gather(metric, expected)

# Run bootstrap
df_any <- 
  foreach(1:params$n, .combine = bind_rows, .packages = pkgs) %dorng%
    eval_boot(
      t_tr = true_code,
      t_fs = bind_rows(df_true, df_false),
      type = "active", 
      is_old = F, 
      filters = filtering_vars[0],
      grouping_fs = grouping_vars_false[1],
      pred_label = pred_label_vars[c(1, 4)]
    )

# Summarize
out_code$code_eval_effective <- 
  df_any %>% 
  eval_summarize() %>% 
  left_join(expected_vals)

# Print
out_code$code_eval_effective %>% 
  sable()
```


***


# COI

## Prepare data

```{r}
df_false <- read_excel(file.path(tidy_data, "coi_false.xlsx"))
df_true  <- read_excel(file.path(tidy_data, "coi_true.xlsx"))
```

```{r}
out_coi <- list()
```


Setup variables.

```{r}
# Create variable groupings
filtering_vars <- syms(c(
  "isExplicit",
  "isResearch",
  "is_xml"
))

# Sampling strata for articles initially predicted positive
grouping_vars_true <- syms(c(
  ""
))

# Sampling strata for articles initially predicted negative
grouping_vars_false <- syms(c(
  ""
))

pred_label_vars <- syms(c(
  "is_coi_pred", 
  "isCOI"
))
```


## Evaluate

Any.

```{r}
# Set seed
set.seed(1306)

# Expected value
expected_vals <- 
  eval_no_boot(type = "any", is_old = F, filters = filtering_vars[0]) %>% 
  gather(metric, expected)

# Run bootstrap
df_any <- 
  foreach(1:params$n, .combine = bind_rows, .packages = pkgs) %dorng% 
    eval_boot(type = "any", is_old = F, filters = filtering_vars[0])

# Summarize
out_coi$coi_eval_any <- 
  df_any %>% 
  eval_summarize() %>% 
  left_join(expected_vals)

out_coi$coi_eval_any %>% 
  sable()
```


***


# Fund

## Prepare data

```{r}
df_false <- read_excel(file.path(tidy_data, "fund_false.xlsx"))
df_true  <- read_excel(file.path(tidy_data, "fund_true.xlsx"))
```

```{r}
out_fund <- list()
```


Setup variables.

```{r}
# Create variable groupings
filtering_vars <- syms(c(
  "isExplicit",
  "isResearch",
  "is_xml"
))

# Sampling strata for articles initially predicted positive
grouping_vars_true <- syms(c(
  ""
))

# Sampling strata for articles initially predicted negative
grouping_vars_false <- syms(c(
  ""
))

pred_label_vars <- syms(c(
  "is_funded_pred", 
  "isFunding"
))
```


## Evaluate

Any.

```{r}
# Set seed
set.seed(1306)

# Expected value
expected_vals <- 
  eval_no_boot(type = "any", is_old = F, filters = filtering_vars[0]) %>% 
  gather(metric, expected)

# Run bootstrap
df_any <- 
  foreach(1:params$n, .combine = bind_rows, .packages = pkgs) %dorng% 
    eval_boot(type = "any", is_old = F, filters = filtering_vars[0])

# Summarize
out_fund$fund_eval_any <- 
  df_any %>% 
  eval_summarize() %>% 
  left_join(expected_vals)

# Print
out_fund$fund_eval_any %>% 
  sable()
```


***


# Register

## Prepare data

```{r}
df_false <- read_excel(file.path(tidy_data, "register_false.xlsx"))
df_true  <- read_excel(file.path(tidy_data, "register_true.xlsx"))
```

```{r}
out_register <- list()
```


Setup variables.

```{r}
# Create variable groupings
filtering_vars <- syms(c(
  "isExplicit",
  "isResearch",
  "is_xml"
))

grouping_vars_true <- syms(c(
  ""
))

grouping_vars_false <- syms(c(
  "is_relevant", 
  "is_method",
  "is_NCT",
  "is_register_pred"
))

pred_label_vars <- syms(c(
  "is_register_pred", 
  "is_register"
))
```


## Evaluate

Any.

```{r}
# Set seed
set.seed(1306)

# Expected value
expected_vals <- 
  eval_no_boot() %>% 
  gather(metric, expected)

# Run bootstrap
df_any <- 
  foreach(1:params$n, .combine = bind_rows, .packages = pkgs) %dorng% 
    eval_boot()

# Summarize
out_register$reg_eval_any <- 
  df_any %>% 
  eval_summarize() %>% 
  left_join(expected_vals)

# Print
out_register$reg_eval_any %>% 
  sable()
```


***


# Fig 2: Evaluation summary

## Prepare data

```{r}
eval_tables <- list(
  COI = out_coi$coi_eval_any,
  Funding = out_fund$fund_eval_any,
  Registration = out_register$reg_eval_any,
  Data = out_data$data_eval_active,
  Code = out_code$code_eval_effective
) 

eval_metrics <- eval_tables %>% bind_rows(.id = "Indicator")
```


## Plot performance

```{r}
# Select metrics
unwanted_metrics <- 
  c("FN", "FP", "TP", "TN", "AUROC", "P", "P_pred", "P_error", "P_true")

# Color palette
colfunc <- colorRampPalette(c("white", "red"))


p1 <- 
  eval_metrics %>% 
  filter(!metric %in% unwanted_metrics) %>% 
  mutate(vals = sprintf("%0.1f%% \n(%0.1f%%-%0.1f%%)", expected, lo, hi)) %>% 
  ggplot(aes(x = Indicator, y = metric, fill = expected, label = vals)) +
  geom_tile(aes(width = 0.99, height = 0.99)) +
  # scale_color_gradientn(colours = alpha(colfunc(10), 0.8)) +
  # scale_fill_continuous(limit=c(50, 100), low = "#F8766D", high = "#00BA38") +
  scale_fill_continuous(limit = c(0, 100), low = "red", high = "lightgreen") +
  geom_text(size = 3) +
  scale_x_discrete(position = "top", expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  labs(x = NULL, y = NULL) +
  theme(
    axis.line = element_blank(),
    axis.text.x  = element_text(margin = ggplot2::margin(t = 10)),
    axis.text.y  = element_text(margin = ggplot2::margin(l = 20)),
    legend.position = "none",
    panel.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    plot.margin = unit(c(0, 0, 0, 0), "cm")
  )
```


## Plot prevalence

```{r}
# Define names
p_names <- c(
  P_error = "Error", 
  P_pred = "Prevalence (estimated)", 
  P_true = "Prevalence (true)"
)

# Create palette
colfunc <- colorRampPalette(c("lightgrey", "lightslategray"))

# Get figure
p2 <- 
  eval_metrics %>% 
  filter(metric %in% c("P_pred", "P_error", "P_true")) %>% 
  mutate(vals = sprintf("%0.1f%% \n(%0.1f%%-%0.1f%%)", expected, lo, hi)) %>% 
  mutate_at(vars(metric), recode, !!! p_names) %>% 
  ggplot(aes(x = Indicator, y = metric, label = vals, fill = expected)) +
  geom_tile(aes(width = 0.99, height = 0.99)) +
  geom_text(size = 3) +
  scale_x_discrete(expand = c(0, 0)) +
  scale_y_discrete(expand = c(0, 0)) +
  scale_fill_gradientn(colours = alpha(colfunc(10), 0.8)) +
  # scale_fill_manual(values = "lightblue") +
  labs(x = NULL, y = NULL) +
  theme(
    axis.line = element_blank(),
    axis.text.x  = element_blank(),
    axis.text.y  = element_text(margin = ggplot2::margin(l = 20)),
    legend.position = "none",
    panel.background = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    plot.margin = unit(c(0.11, 0, 0, 0), "cm")
  )
```


## Join

```{r}
# Plot
cowplot::plot_grid(p1, p2, nrow = 2, align = "v", rel_heights = c(2, 1))

# Save
ggsave(
  file.path(figure_output, "paper_fig-2_algorithm-evaluation.jpg"), 
  width = 7
)
```


***


# Documentation {.tabset}

## Session Info

```{r session_info, echo=FALSE}
print(sessionInfo(), locale = F)
```


## References

```{r refs, echo=FALSE}
(.packages()) %>% sort %>% lapply(citation) %>% lapply(c) %>% unique
```
